"""Clean workflow engine schema

Revision ID: 2542aaa2426b
Revises: 
Create Date: 2025-07-30 10:15:47.693470

"""
from alembic import op
import sqlalchemy as sa

# revision identifiers, used by Alembic.
revision = '2542aaa2426b'
down_revision = None
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('users',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('email', sa.String(length=255), nullable=False),
    sa.Column('password_hash', sa.String(length=255), nullable=False),
    sa.Column('is_active', sa.Boolean(), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=True),
    sa.Column('updated_at', sa.DateTime(), nullable=True),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('email')
    )
    op.create_table('workflow_agents',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('name', sa.String(length=255), nullable=False),
    sa.Column('description', sa.Text(), nullable=True),
    sa.Column('agent_type', sa.Enum('DATA_PROCESSING', 'WEB_SCRAPING', 'API_AUTOMATION', 'ML_PIPELINE', 'CUSTOM', 'WORKFLOW', name='agenttype'), nullable=False),
    sa.Column('status', sa.Enum('ACTIVE', 'PAUSED', 'ERROR', 'INACTIVE', name='agentstatus'), nullable=False),
    sa.Column('workflow_data', sa.JSON(), nullable=True),
    sa.Column('auto_execute', sa.Boolean(), nullable=True),
    sa.Column('execution_interval', sa.Integer(), nullable=True),
    sa.Column('max_executions', sa.Integer(), nullable=True),
    sa.Column('trigger_type', sa.Enum('DATA_CHANGE', 'API_WEBHOOK', 'SCHEDULE', 'THRESHOLD', 'FILE_CHANGE', 'MANUAL', name='triggertype'), nullable=True),
    sa.Column('trigger_config', sa.JSON(), nullable=True),
    sa.Column('actions', sa.JSON(), nullable=True),
    sa.Column('notification_channels', sa.JSON(), nullable=True),
    sa.Column('notification_config', sa.JSON(), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=True),
    sa.Column('updated_at', sa.DateTime(), nullable=True),
    sa.Column('created_by', sa.String(length=255), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('agent_workflows',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('agent_id', sa.Integer(), nullable=False),
    sa.Column('user_id', sa.Integer(), nullable=False),
    sa.Column('name', sa.String(length=255), nullable=False),
    sa.Column('nodes', sa.JSON(), nullable=False),
    sa.Column('edges', sa.JSON(), nullable=False),
    sa.Column('created_at', sa.DateTime(), nullable=True),
    sa.Column('updated_at', sa.DateTime(), nullable=True),
    sa.ForeignKeyConstraint(['agent_id'], ['workflow_agents.id'], ),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('monitoring_jobs',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('agent_id', sa.Integer(), nullable=False),
    sa.Column('user_id', sa.Integer(), nullable=False),
    sa.Column('name', sa.String(length=255), nullable=False),
    sa.Column('url', sa.String(length=2048), nullable=False),
    sa.Column('selectors', sa.JSON(), nullable=False),
    sa.Column('frequency', sa.Integer(), nullable=True),
    sa.Column('change_threshold', sa.Float(), nullable=True),
    sa.Column('is_active', sa.Boolean(), nullable=True),
    sa.Column('last_check', sa.DateTime(), nullable=True),
    sa.Column('last_content_hash', sa.String(length=64), nullable=True),
    sa.Column('consecutive_failures', sa.Integer(), nullable=True),
    sa.Column('total_checks', sa.Integer(), nullable=True),
    sa.Column('total_changes_detected', sa.Integer(), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=True),
    sa.Column('updated_at', sa.DateTime(), nullable=True),
    sa.ForeignKeyConstraint(['agent_id'], ['workflow_agents.id'], ),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('workflow_executions',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('agent_id', sa.Integer(), nullable=False),
    sa.Column('user_id', sa.Integer(), nullable=False),
    sa.Column('started_at', sa.DateTime(), nullable=True),
    sa.Column('completed_at', sa.DateTime(), nullable=True),
    sa.Column('status', sa.String(length=20), nullable=True),
    sa.Column('error_message', sa.Text(), nullable=True),
    sa.Column('workflow_nodes', sa.JSON(), nullable=False),
    sa.Column('workflow_edges', sa.JSON(), nullable=False),
    sa.ForeignKeyConstraint(['agent_id'], ['workflow_agents.id'], ),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('change_records',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('monitoring_job_id', sa.Integer(), nullable=False),
    sa.Column('selector', sa.String(length=500), nullable=True),
    sa.Column('label', sa.String(length=255), nullable=True),
    sa.Column('old_value', sa.Text(), nullable=True),
    sa.Column('new_value', sa.Text(), nullable=True),
    sa.Column('change_type', sa.String(length=50), nullable=True),
    sa.Column('detected_at', sa.DateTime(), nullable=True),
    sa.Column('notification_sent', sa.Boolean(), nullable=True),
    sa.ForeignKeyConstraint(['monitoring_job_id'], ['monitoring_jobs.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('node_executions',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('execution_id', sa.Integer(), nullable=False),
    sa.Column('node_id', sa.String(length=255), nullable=False),
    sa.Column('node_type', sa.String(length=50), nullable=False),
    sa.Column('started_at', sa.DateTime(), nullable=True),
    sa.Column('completed_at', sa.DateTime(), nullable=True),
    sa.Column('status', sa.String(length=20), nullable=True),
    sa.Column('error_message', sa.Text(), nullable=True),
    sa.Column('input_config', sa.JSON(), nullable=True),
    sa.Column('output_data', sa.JSON(), nullable=True),
    sa.Column('node_specific_data', sa.JSON(), nullable=True),
    sa.ForeignKeyConstraint(['execution_id'], ['workflow_executions.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('workflow_nodes',
    sa.Column('id', sa.String(length=255), nullable=False),
    sa.Column('workflow_id', sa.Integer(), nullable=False),
    sa.Column('node_type', sa.String(length=50), nullable=False),
    sa.Column('position_x', sa.Float(), nullable=False),
    sa.Column('position_y', sa.Float(), nullable=False),
    sa.Column('data', sa.JSON(), nullable=False),
    sa.Column('configured', sa.Boolean(), nullable=True),
    sa.Column('monitoring_job_id', sa.Integer(), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=True),
    sa.Column('updated_at', sa.DateTime(), nullable=True),
    sa.ForeignKeyConstraint(['monitoring_job_id'], ['monitoring_jobs.id'], ),
    sa.ForeignKeyConstraint(['workflow_id'], ['agent_workflows.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('ml_models',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('node_execution_id', sa.Integer(), nullable=False),
    sa.Column('model_type', sa.String(length=50), nullable=False),
    sa.Column('model_name', sa.String(length=200), nullable=True),
    sa.Column('feature_names', sa.JSON(), nullable=False),
    sa.Column('target_name', sa.String(length=100), nullable=False),
    sa.Column('n_features', sa.Integer(), nullable=False),
    sa.Column('n_samples', sa.Integer(), nullable=False),
    sa.Column('train_size', sa.Integer(), nullable=False),
    sa.Column('test_size', sa.Integer(), nullable=False),
    sa.Column('model_config', sa.JSON(), nullable=True),
    sa.Column('training_metrics', sa.JSON(), nullable=False),
    sa.Column('model_metadata', sa.JSON(), nullable=True),
    sa.Column('model_file_path', sa.String(length=500), nullable=False),
    sa.Column('model_file_size', sa.Integer(), nullable=True),
    sa.Column('preprocessing_notes', sa.Text(), nullable=True),
    sa.Column('user_instructions', sa.Text(), nullable=True),
    sa.Column('tokens_used', sa.Integer(), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=False),
    sa.Column('updated_at', sa.DateTime(), nullable=True),
    sa.ForeignKeyConstraint(['node_execution_id'], ['node_executions.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id')
    )
    with op.batch_alter_table('ml_models', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('ix_ml_models_created_at'), ['created_at'], unique=False)
        batch_op.create_index(batch_op.f('ix_ml_models_model_type'), ['model_type'], unique=False)

    op.create_table('ml_model_predictions',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('model_id', sa.Integer(), nullable=False),
    sa.Column('input_data', sa.JSON(), nullable=False),
    sa.Column('predictions', sa.JSON(), nullable=False),
    sa.Column('prediction_metadata', sa.JSON(), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=False),
    sa.ForeignKeyConstraint(['model_id'], ['ml_models.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id')
    )
    with op.batch_alter_table('ml_model_predictions', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('ix_ml_model_predictions_created_at'), ['created_at'], unique=False)

    op.create_table('ml_training_data',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('model_id', sa.Integer(), nullable=False),
    sa.Column('features_data', sa.JSON(), nullable=False),
    sa.Column('targets_data', sa.JSON(), nullable=False),
    sa.Column('visualization_data', sa.JSON(), nullable=True),
    sa.Column('data_split', sa.String(length=20), nullable=False),
    sa.Column('created_at', sa.DateTime(), nullable=False),
    sa.ForeignKeyConstraint(['model_id'], ['ml_models.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id')
    )
    with op.batch_alter_table('ml_training_data', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('ix_ml_training_data_data_split'), ['data_split'], unique=False)

    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('ml_training_data', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_ml_training_data_data_split'))

    op.drop_table('ml_training_data')
    with op.batch_alter_table('ml_model_predictions', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_ml_model_predictions_created_at'))

    op.drop_table('ml_model_predictions')
    with op.batch_alter_table('ml_models', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_ml_models_model_type'))
        batch_op.drop_index(batch_op.f('ix_ml_models_created_at'))

    op.drop_table('ml_models')
    op.drop_table('workflow_nodes')
    op.drop_table('node_executions')
    op.drop_table('change_records')
    op.drop_table('workflow_executions')
    op.drop_table('monitoring_jobs')
    op.drop_table('agent_workflows')
    op.drop_table('workflow_agents')
    op.drop_table('users')
    # ### end Alembic commands ###
